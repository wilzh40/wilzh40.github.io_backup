---
layout: post
title: Video Capture with Sibernetics
description: ""
category: null
tags: []
published: true
---

{% include JB/setup %}

### Sibernetics runs like a snail

Thus, to properly render simulation results, I have to make sure that the modeling is in fact readable and able to be analyzed before I change the input (namely, connecting the .dat file generated by `c302_A.py` from `jnml` and the CElegansNeuroML project). Problem is, it runs at 2 fps. 
With optirun by using Bumblebee that utilizes my _Nvidia G555M_ optimum graphics card, at best it does about 4 fps. That means it will take about 12 hours to record 1 second of movement validation.

That means I need to screen capture. I decided to use [kdenlive](http://www.kdenlive.org/), an extensive open-source video capturing and editing software, and then hopefully condense that simulation into a timelapse to properly view the results. 